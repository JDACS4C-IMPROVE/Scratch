
:toc:

= High Error Drug (HED) Workflow

== Quick start

. `upf-uno-heds.sh` is the main user script.
. Obtain data, set this location as `DATA_SOURCE` in `upf-uno-heds.sh` .
. Set output location `CANDLE_DATA_DIR` in `upf-uno-heds.sh` .
. Set the software locations in `upf-uno-heds.sh` .
. Set system settings in `cfg-sys-1.sh` (or in the environment).
. Make your `UPF`, possibly using `gen-json`.  This is the list of hyperparameters that vary by run.
. Edit your `DFLTS` file as necessary.  This is the list of hyperparameters that do not vary by run.
. Run with:
+
----
$ ./upf-uno-heds.sh aurora UPF DFLTS
----

== Feature overview

. Uses IMPROVE-compliant data and CANDLE-compliant model.
. Totally parallel, load-balanced, run-anywhere behavior during workflow run.  Any size job can be submitted.
. Checkpointing at workflow (whole RUN) and model training (epoch) level (via CANDLE checkpoint module).
. Parallel data staging to local FS via MPI-IO.
. Parallel TensorFlow software staging to local FS via MPI-IO (16 GB!).
. All data manipulation (`partition_uno_pq`) in local FS.
. Output data organized into EXP and RUN directories.
. Performance monitoring may be enabled using in `model_runner`.
. Use of 12 tiles per node on Aurora, easily reconfigurable via `PPN`.
. All in-memory execution - once loaded, all software and data is reused within the same Python instances, 1 per GPU tile.

== Workflow behavior

*Overall idea:*
For one EXP, each line in the `UPF` is merged with the JSON in the `DFLTS` file to create a hyperparameter set for a RUN.  Each `index` in the `UPF` is provided to `partition_uno_pq.py` to punch out a drug and put it in the test set.  Each RUN trains a model on the data set and reports the test scores.

The data flows through the <<data-locations,data locations>> described below.  Each EXP runs in a unique EXPID created under `CANDLE_DATA_DIR`.  Each RUN has a unique hyperparameter set that the model uses, and is put in a subdirectory of `CANDLE_DATA_DIR/run`, along with logs, checkpoints, and metadata.

. At workflow startup,
.. the TensorFlow environment is broadcasted to the local FS.
.. all training data is broadcasted from `DATA_SOURCE` to `TMP-ORIGINAL`.
. For each RUN, data is partitioned from `TMP-ORIGINAL` to `TMP-INSTANCE` by `model_runner` -> `hed_setup` -> `partition_uno_pq`.
. Training runs on the data in `TMP-INSTANCE`.
. Outputs go directly to the RUN directory on the PFS.

== Data locations

PFS is the shared, persistent, parallel file system.

`DATA_SOURCE`::
Original data in PFS.  This is a preprocessed IMPROVE data set.

`TMP-ORIGINAL`::
`/tmp/$USER/original`: location that data is loaded into from `DATA_SOURCE` by `hook-leader.tcl` .
Specified by hyperparameter `input_dir` .
Hard-coded in `hook-leader.tcl` and `dflts-*.json` .

`TMP-INSTANCE`::
`/tmp/$USER/index-00N`: location for partitioned data from `partition_uno_pq`.
`hed_setup` changes `input_dir` to this directory.
This is also the hyperparameter `instance_directory` and `output_dir` for the model run.
Set by `hed_setup`.

== Components and controls

`upf-uno-heds.sh`::
The main user interface script.  Controls:
+
. `DATA_SOURCE`
. Software locations for IMPROVE and Uno

`cfg-sys-1.sh`::
System settings.  Controls:
+
. `PROCS`: The process count (number of ranks, including 1 server)
. `PPN`: The processes-per-node number
. `QUEUE`: The queue to use
+
All of these may be set in the user environment as well, which takes precedence.

`UPF`::
(Unrolled Parameter File: A hard-coded list of hyperparameters to run.)  The list of JSON hyperparameter sets to run.  One JSON fragment per line.  Generated by `gen-jsons.py`

`DFLTS`::
The JSON hyperparameters to run for every instance.  Each instance combines this set with a set from the UPF.  Settings include `epochs`, `input_dir`==`TMP-ORIGINAL`.  Could be extended with other model hyperparameters, which will override Uno's `uno_default_model.txt`.

`hed_setup`::
Sets up and tears down the training run.  Called by Supervisor's `model_runner.py`.  No user controls.
+
. Before the run:
.. Calls `partition_uno_pq.py` to partition `rsp_merged.parquet` into `rsp_{train,val,test}_data.parquet` using the `index`.
. Sets up all training data in the `TMP-INSTANCE` location.
.. Sets up the XPU for Aurora
. After the run:
.. Touches the marker file for this `index` to prevent restart
.. Unlinks the `TMP-INSTANCE` files to save space.

`partition_uno_pq`::
Derived from Brettin's `create_uno_h5` module, but 1) modified for IMPROVE Parquet files and 2) packaged as a library for use by Supervisor's `model_runner`.

== Checkpointing

This Uno has the CANDLE `ckpt` module, so models are saved each epoch, about once per hour.  Old models beyond the last 3 epochs are automatically deleted.

To restart from an existing EXP, simply provide:

----
$ ./upf-uno-heds.sh aurora UPF DFLTS EXP
----

A new EXP will be created.  The old EXP will not be modified.  The old EXP RUNs are simply copied into the new EXP.  The Supervisor `model_runner` will skip any completed runs with a `marker` file, and the CANDLE `ckpt` module will automatically restart from any models in the RUNs.

== Aurora

Aurora GPU settings are set in:

. Supervisor `env-aurora.sh`
. `hed_setup`: `cfg_xpu()`

These settings automatically run on any number of GPUs up to 12.  Simply set `PROCS` and `PPN` as described above.

== Installation

On Aurora, you can simply use the Swift/T and Supervisor installations that exist and are coded in `upf-uno-hed.sh`.  The IMPROVE library is already pip-installed in the TensorFlow environment.  This is specified by the Swift/T installation.

Clone the "HED workflow scripts" from `git@github.com:JDACS4C-IMPROVE/Scratch.git` , directory `/hed/` .

Clone Wozniak's fork of IMPROVE-UNO from `git@github.com:j-woz/UNO.git` .  This contains some new features for CANDLE `ckpt` and our inferencing approach.  We are working with Rajeev Jain to merge these back in to Uno.

Specify these locations in the main script `upf-uno-heds.sh`.

== Analysis scripts

Pick an EXP and set:
----
$ D=/path/to/EXP00N
----

`shrink-logs.sh`::
Converts the logs `out-{asterisk}.txt` to `summary-{asterisk}.txt`, removing TensorFlow junk.
Reduces file size by about 99%.
Run with:
+
----
$ shrink-logs.sh $D/out
----
+

`epochs.sh`::
Report completed epochs for all RUNs.
Requires `summary-*.txt` .
Run with `epochs.sh $D 1` .
Writes result in `$D/epochs.txt` .

`progress.sh`::
Report progress summary for this EXP.
Requires `summary-*.txt` .
Run with `progress.sh $D` .
Writes result in `$D/progress.txt` .

`extract.py`::
Extract the test scores for this EXP.
Run with `extract.py $D` .

`export.sh`::
Export the key logs and results for this EXP into a TGZ.
Run with `export.sh $D` .
Creates `$D/EXP___.tgz` .

`clean-ckpts.sh`::
Remove older checkpoint files, as CANDLE `ckpt` does not remove checkpoints created by prior runs.  Run with:
+
----
$ clean-ckpts.sh $D N
----
+
where `N` is the number of recent checkpoints to retain.  Typically set `N=3`.

`list_drugs.py`::
Produce a list that maps all valid indices to all drug names in the given RSP Parquet file.

`top_drugs.sh`::
Reports the top `COUNT` drugs (lowest AUC) for the given `CELL`, where `TYPE` is `true` or `pred`.
Run with:
+
----
$ top_drugs.sh DIR TYPE CELL COUNT
----

== Data science scripts

Required Python libraries:

Conda:
----
numpy
pandas
tqdm
tensorflow
scikit-learn
polars
matplotlib
plotnine
seaborn
----

== Study for WORKS paper

Here we apply the HED workflow to the whole dataset to attempt to improve predicted sorting performance for new drugs.

=== Run the workflow

We ran the workflow using the UPF file like this:

----
{"id": "RUN000", "index": 0}
{"id": "RUN001", "index": 1}
{"id": "RUN002", "index": 2}
...
----

There are 770 unique drugs in the dataset, so there are runs from `RUN000` to `RUN769`.  The `index` is passed to `partition_uno_pq.py` with `by_drug`.  Thus, each single drug makes a test set.

The defaults file looks like:

----
{
  "epochs": 20,
  "input_dir":   "/tmp/wozniak/original",
  "pre_module":  "hed_setup",
  "post_module": "hed_setup"
}
----

The output directory looks like:

----
   0  /home/wozniak/C/out/unorun/Output/EXP011
   1  ├── [ 205 2025-07-17]  dflts-e20-a6.json
   2  ├── [353M 2025-08-04]  EXP011.tgz
   3  ├── [ 23K 2025-07-17]  hed-gen-770.json
   4  ├── [  56 2025-07-17]  jobid.txt
 776  ├── [ 52K 2025-07-17]  out
 842  │   ├── [546K 2025-07-17]  out-000.txt
 843  │   ├── [540K 2025-07-17]  out-001.txt
 844  │   ├── [540K 2025-07-17]  out-002.txt
...
1626  ├── [ 36K 2025-07-17]  run
1627  │   ├── [4.0K 2025-07-17]  RUN000
1628  │   │   ├── [4.0K 2025-07-17]  ckpts
1629  │   │   │   ├── [  89 2025-07-17]  best -> /lus/flare/projects/candle_aesp_CNDA/out/unorun/Output/EXP283/run/RUN000/ckpts/epochs/002
1630  │   │   │   ├── [ 18K 2025-07-17]  ckpt.log
1631  │   │   │   ├── [4.0K 2025-07-17]  epochs
1632  │   │   │   │   ├── [4.0K 2025-07-17]  002
1633  │   │   │   │   │   └── [ 226 2025-07-17]  ckpt-info.json
1665  │   │   │   │   └── [4.0K 2025-07-17]  020
1666  │   │   │   │       ├── [ 227 2025-07-17]  ckpt-info.json
1667  │   │   │   │       └── [ 65M 2025-07-17]  model.h5
1668  │   │   │   └── [  89 2025-07-17]  last -> /lus/flare/projects/candle_aesp_CNDA/out/unorun/Output/EXP011/run/RUN000/ckpts/epochs/020
...
1669  │   │   ├── [ 495 2025-07-17]  history.txt
1670  │   │   ├── [3.9K 2025-07-17]  parameters.txt
1671  │   │   ├── [   4 2025-07-17]  rank.txt
1672  │   │   ├── [  22 2025-07-17]  result.txt
1673  │   │   ├── [  21 2025-07-17]  stop.marker
1674  │   │   ├── [ 129 2025-07-17]  test_scores.json
1675  │   │   ├── [ 90K 2025-07-17]  test_y_data_predicted.csv
1676  │   │   ├── [ 128 2025-07-17]  val_scores.json
1677  │   │   └── [6.2M 2025-07-17]  val_y_data_predicted.csv
1678  │   ├── [4.0K 2025-08-01]  RUN001
1678  │   ├── [4.0K 2025-08-01]  RUN002
...
----

That is for `EXP011`, which had the settings specified in https://docs.google.com/spreadsheets/d/1aBKNut_HRZEyLnOANBMzJ3O086mJ901KAmDvFsRG5PY[this spreadsheet].

The `out-*.txt` files have the output streams from each rank.  This is just for debugging.  Real output is in the `run/RUN*` directories.  This includes `test_y_data_predicted.csv`, which looks like:

----
# run/RUN123/test_y_data_predicted.csv
auc_true,auc_pred,labels
0.9168,0.3117,P17_VanDerWeltering
0.9168,0.3117,P17_VanDerWeltering
...
0.9145,0.3117,ACH-000956
0.9145,0.3117,ACH-000956
...
0.9121,0.3117,ACH-000948
0.9121,0.3117,ACH-000948
...
----

The `labels` are the `CELLs`.  So this gives us the scores for all samples of the drug for `RUN123` with all the `CELLs`.  We can simply `cat` all these files together to collect statistics.
